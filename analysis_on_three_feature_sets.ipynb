{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.cross_decomposition import CCA\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, I load the data…\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_paths = glob.glob(\"three_feature_folder/*.p\")\n",
    "#print(file_paths)\n",
    "contents = []\n",
    "\n",
    "for f in file_paths:\n",
    "    contents.append(pickle.load(open(f,'rb')))\n",
    "print(contents)\n",
    "print(contents[0]['dm'].columns)\n",
    "print(contents[0]['efel'].columns)\n",
    "print(contents[0]['allen'].columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Then, I do a cleanup step…\n",
    "### fix fact that column names may be NU classes as opposed to strings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rename = {}\n",
    "\n",
    "def clean_data_formating(contents):\n",
    "    for col in contents[0]['dm'].columns:\n",
    "        if hasattr(col,'name'):\n",
    "            rename[col] = col.name\n",
    "        else:\n",
    "            rename[col] = col\n",
    "    for cont in contents:\n",
    "        cont['dm'].rename(columns=rename, inplace=True)\n",
    "        #print(cont['dm'].columns)\n",
    "    return contents\n",
    "contents = clean_data_formating(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now I try to align and merge the data frames\n",
    "\n",
    "This is much like merging and aligning the excell spreadsheets.\n",
    "\n",
    "I try to find features that should be the same across feature space like Coefficient of variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                        ALLEN  \\\n",
      "CV15        0    0.048026\n",
      "0    0.182765\n",
      "Name: isi_cv, dtyp...   \n",
      "CV3                                                  0.182765   \n",
      "adaption3                                        -0.000207387   \n",
      "adaption15                                            1.00174   \n",
      "4                                                     0.99995   \n",
      "\n",
      "                              DM                   EFEL  protocol  \n",
      "CV15                     5.47136               0.184659       1.5  \n",
      "CV3                      5.47136              0.0449844       3.0  \n",
      "adaption3               -29.1667  [0.00765320288822377]       1.5  \n",
      "adaption15  1.759999999999991 ms   [0.7921875001590024]       3.0  \n",
      "4           1.759999999999991 ms   [2.1921875001593207]       1.5  \n"
     ]
    }
   ],
   "source": [
    "CV_DM = contents[0]['dm']['ISICVTest'].iloc[0]\n",
    "accom_DM = contents[0]['dm']['InitialAccommodationMeanTest'].iloc[0]\n",
    "inrh = contents[0]['dm']['InputResistanceTest'].iloc[0]\n",
    "delay = contents[0]['dm']['AP1DelayMeanTest'].iloc[0]\n",
    "\n",
    "# Allen\n",
    "ALLEN_CV15 = contents[0]['allen']['isi_cv'][0]#.iloc[0]\n",
    "ALLEN_CV30 = contents[0]['allen']['isi_cv'][1]#.iloc[1]\n",
    "\n",
    "\n",
    "ahp = contents[0]['efel']['AHP_depth']\n",
    "spwidth = contents[0]['efel']['spike_half_width']\n",
    "\n",
    "\n",
    "adaptation_index_EFEL = contents[0]['efel']['adaptation_index']\n",
    "daptation_index2_EFEL = contents[0]['efel']['adaptation_index2']\n",
    "sag_amplitude_EFEL = contents[0]['efel']['sag_amplitude']\n",
    "irregularity_index_EFEL = contents[0]['efel']['irregularity_index']\n",
    "time_to_first_spike_EFEL = contents[0]['efel']['time_to_first_spike']\n",
    "\n",
    "EFEL_ISI_CV_15 = contents[0]['efel']['ISI_CV'].iloc[0]\n",
    "EFEL_ISI_CV_30 = contents[0]['efel']['ISI_CV'].iloc[1]\n",
    "\n",
    "#aligned_f = pd.DataFrame(columns=['protocol','EFEL','DM','ALLEN'])\n",
    "aligned_frame = []\n",
    "#aligned_f = pd.DataFrame()\n",
    "temp = {'protocol':1.5,'EFEL':float(EFEL_ISI_CV_15[0]),'DM':CV_DM,'ALLEN':ALLEN_CV15[0]}\n",
    "#aligned_f.append(temp,ignore_index=True)#'cv1.5')\n",
    "\n",
    "aligned_frame.append(temp)\n",
    "\n",
    "temp = {'protocol':3.0,'ALLEN':ALLEN_CV30.iloc[-1],'DM':CV_DM,'EFEL':float(EFEL_ISI_CV_30[0])}\n",
    "aligned_frame.append(temp)\n",
    "\n",
    "#aligned_f.append(temp,ignore_index=True)#index='cv3.0')\n",
    "#print(aligned_f)\n",
    "\n",
    "#import pdb\n",
    "#pdb.set_trace()\n",
    "temp = {'protocol':3.0,'EFEL':adaptation_index_EFEL.iloc[-1],'DM':accom_DM,'ALLEN':contents[0]['allen']['adapt'].iloc[-1]}\n",
    "#aligned_f = aligned_frame.append(temp)\n",
    "\n",
    "temp = {'protocol':1.5,'EFEL':adaptation_index_EFEL.iloc[0],'DM':accom_DM,'ALLEN':contents[0]['allen']['adapt'].iloc[0]}\n",
    "aligned_frame.append(temp)\n",
    "\n",
    "\n",
    "temp = {'protocol':3.0,'EFEL':time_to_first_spike_EFEL.iloc[-1],'DM':delay,'ALLEN':contents[0]['allen']['latency'].iloc[-1]}\n",
    "aligned_frame.append(temp)\n",
    "temp = {'protocol':1.5,'EFEL':time_to_first_spike_EFEL.iloc[0],'DM':delay,'ALLEN':contents[0]['allen']['latency'].iloc[0]}\n",
    "aligned_frame.append(temp)\n",
    "\n",
    "af = pd.DataFrame(aligned_frame)\n",
    "af.rename(index={1:'CV3'}, inplace=True)\n",
    "af.rename(index={0:'CV15'}, inplace=True)\n",
    "af.rename(index={3:'adaption15'}, inplace=True)\n",
    "af.rename(index={2:'adaption3'}, inplace=True)\n",
    "af.rename(index={2:'delay3'}, inplace=True)\n",
    "af.rename(index={2:'delay15'}, inplace=True)\n",
    "\n",
    "#print(af['ALLEN'].corr(af['DM']))\n",
    "\n",
    "#print(af.corr())\n",
    "print(af)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_three_vectors(three_vectors,title=None):\n",
    "    plot_vector = [i for i,_ in enumerate(three_vectors[0])]\n",
    "    for tv in three_vectors:\n",
    "        tv = (tv - np.mean(tv))/np.std(tv)\n",
    "        plt.plot(plot_vector,tv)\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "efel_CV = [ float(cont['efel']['ISI_CV'].iloc[0]) for cont in contents ]\n",
    "dm_CV = [ float(cont['dm']['ISICVTest'].iloc[0]) for cont in contents ]\n",
    "allen_CV = [ float(cont['allen']['isi_cv'].iloc[0]) for cont in contents ]\n",
    "\n",
    "scaled_allen_CV = (allen_CV - np.mean(allen_CV))/np.std(allen_CV)\n",
    "scaled_dm_CV = (dm_CV - np.mean(dm_CV))/np.std(dm_CV)\n",
    "#sklearn.preprocessing.scale(, axis=0, with_mean=True, with_std=True, copy=True)\n",
    "scaled_efel_CV = (efel_CV - np.mean(efel_CV))/np.std(efel_CV)\n",
    "three_vectors = [scaled_allen_CV, scaled_dm_CV,scaled_efel_CV]\n",
    "plot_three_vectors(three_vectors,title='CV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-853ee88e7deb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mefel_CV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm_CV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdm_CV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallen_CV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mcca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m                   \u001b[0;31m# (5,5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cca' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#sklearn.preprocessing.scale(efel_CV, axis=0, with_mean=True, with_std=True, copy=True)\n",
    "\n",
    "plt.show()\n",
    "X = list(zip(efel_CV, dm_CV))\n",
    "Y = list(zip(dm_CV,allen_CV))\n",
    "cca.fit(X,Y)\n",
    "\n",
    "cca.coef_.shape                   # (5,5)\n",
    "\n",
    "U_c, V_c = cca.transform(X, Y)\n",
    "\n",
    "U_c.shape                         # (100,1)\n",
    "V_c.shape                         # (100,1)\n",
    "##\n",
    "# wrong because needs different trace\n",
    "##\n",
    "inrh = contents[0]['efel']['ohmic_input_resistance']\n",
    "##\n",
    "# DM\n",
    "CV_DM = contents[0]['dm']['ISICVTest'].iloc[0]\n",
    "accom_DM = contents[0]['dm']['InitialAccommodationMeanTest'].iloc[0]\n",
    "inrh = contents[0]['dm']['InputResistanceTest'].iloc[0]\n",
    "delay = contents[0]['dm']['AP1DelayMeanTest'].iloc[0]\n",
    "\n",
    "# Allen\n",
    "ALLEN_CV15 = contents[0]['allen']['isi_cv'][0]#.iloc[0]\n",
    "ALLEN_CV30 = contents[0]['allen']['isi_cv'][1]#.iloc[1]\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "cca = CCA(n_components=1)\n",
    "cca.fit(U, V)\n",
    "\n",
    "cca.coef_.shape                   # (5,5)\n",
    "\n",
    "U_c, V_c = cca.transform(U, V)\n",
    "U_c.shape                         # (100,1)\n",
    "V_c.shape                         # (100,1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLEN_CV30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
