{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.cross_decomposition import CCA\n",
    "import numpy as np\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, I load the dataâ€¦\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try:\n",
    "#    with open('models_and_data.p','rb') as f:\n",
    "#        everything = pickle.load(f)\n",
    "#    print(everything.keys())\n",
    "    \n",
    "#except:\n",
    "#    file_paths = glob.glob(\"three_feature_folder/*.p\")\n",
    "\n",
    "\n",
    "file_paths = glob.glob(\"three_feature_folder/*.p\")\n",
    "nml_data = []\n",
    "\n",
    "for f in file_paths:\n",
    "    nml_data.append(pickle.load(open(f,'rb')))\n",
    "print(nml_data)\n",
    "print(nml_data[0]['dm'].columns)\n",
    "print(nml_data[0]['efel'].columns)\n",
    "print(nml_data[0]['allen'].columns)\n",
    "\n",
    "\n",
    "#file_paths = glob.glob(\"models/*.p\")\n",
    "#nml_models = []\n",
    "\n",
    "#for f in file_paths:\n",
    "#    nml_models.append(pickle.load(open(f,'rb')))\n",
    "#for m in models: print(m.information)\n",
    "\n",
    "\n",
    "file_paths = glob.glob(\"allen_three_feature_folder/*.p\")\n",
    "allen_analysis = []\n",
    "\n",
    "for f in file_paths:\n",
    "    allen_analysis.append(pickle.load(open(f,'rb')))\n",
    "#print(allen_analysis)\n",
    "\n",
    "#everything = {'allen_data':allen_analysis,'nml_models':nml_data,'nml_data':nml_models}\n",
    "#with open('models_and_data.p','wb') as f:\n",
    "#    pickle.dump(everything,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everything = {'allen_data':allen_analysis,'nml_models':models,'nml_data':nml_models}\n",
    "with open('models_and_data.p','wb') as f:\n",
    "    pickle.dump(everything,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Allen specific data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_paths = glob.glob(\"allen_three_feature_folder/*.p\")\n",
    "allen_analysis = []\n",
    "\n",
    "for f in file_paths:\n",
    "    allen_analysis.append(pickle.load(open(f,'rb')))\n",
    "#print(allen_analysis)\n",
    "\n",
    "allen_analysis[-1]\n",
    "print(allen_analysis[0]['dm'].columns)\n",
    "print(allen_analysis[0]['efel'].columns)\n",
    "print(allen_analysis[0]['allen'].columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(contents[0]['model_id'])\n",
    "print([c['model_id'] for c in contents if 'model_id' in c.keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now I try to align and merge the data frames\n",
    "\n",
    "This is much like merging and aligning the excell spreadsheets.\n",
    "\n",
    "I try to find features that should be the same across feature space like Coefficient of variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in models: print(m.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard = contents[0]['efel'].iloc[0]\n",
    "standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strong = contents[0]['efel'].iloc[1]\n",
    "strong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.iloc[0]\n",
    "#contents[0]['allen'][0]['width']#.iloc[1]\n",
    "#contents[0]['allen']['protocol']\n",
    "contents[-4]['allen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_allens = [c['allen'] for c in contents if 'median_isi' in c['allen'].transpose()]\n",
    "ALLEN_CV15 = [ fa[0]['isi_cv'] for fa in full_allens ]\n",
    "\n",
    "contents[-1]['allen'].keys()#['isi_cv']\n",
    "#[0]['isi_cv']#.iloc[0]\n",
    "#ALLEN_CV30 = contents[0]['allen']['isi_cv'][1]#.iloc[1]\n",
    "#full_allens\n",
    "\n",
    "for c in contents: \n",
    "    cont_ = c['allen'].transpose()\n",
    "    #try:\n",
    "    #    print('yes')\n",
    "        #print(cont_['mean_isi'])\n",
    "    #except:\n",
    "    #    pass\n",
    "    #if 'mea_isi' in cont_:\n",
    "    #    print(c)\n",
    "        \n",
    "        \n",
    "\n",
    "#cont_['mean_isi']\n",
    "    #if 'median_isi' in c['allen']: \n",
    "#ALLEN_CV15\n",
    "#full_allens[0][0].keys()#['median_isi']\n",
    "type(ALLEN_CV15[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_DM = contents[0]['dm']['ISICVTest'].iloc[0]\n",
    "accom_DM = contents[0]['dm']['InitialAccommodationMeanTest'].iloc[0]\n",
    "inrh = contents[0]['dm']['InputResistanceTest'].iloc[0]\n",
    "delay = contents[0]['dm']['AP1DelayMeanTest'].iloc[0]\n",
    "\n",
    "# Allen\n",
    "\n",
    "\n",
    "ahp = contents[0]['efel']['AHP_depth']\n",
    "spwidth = contents[0]['efel']['spike_half_width']\n",
    "\n",
    "\n",
    "adaptation_index_EFEL = contents[0]['efel']['adaptation_index']\n",
    "daptation_index2_EFEL = contents[0]['efel']['adaptation_index2']\n",
    "sag_amplitude_EFEL = contents[0]['efel']['sag_amplitude']\n",
    "irregularity_index_EFEL = contents[0]['efel']['irregularity_index']\n",
    "time_to_first_spike_EFEL = contents[0]['efel']['time_to_first_spike']\n",
    "\n",
    "EFEL_ISI_CV_15 = contents[0]['efel']['ISI_CV'].iloc[0]\n",
    "EFEL_ISI_CV_30 = contents[0]['efel']['ISI_CV'].iloc[1]\n",
    "\n",
    "#aligned_f = pd.DataFrame(columns=['protocol','EFEL','DM','ALLEN'])\n",
    "aligned_frame = []\n",
    "#aligned_f = pd.DataFrame()\n",
    "temp = {'protocol':1.5,'EFEL':float(EFEL_ISI_CV_15[0]),'DM':CV_DM,'ALLEN':ALLEN_CV15[0]}\n",
    "#aligned_f.append(temp,ignore_index=True)#'cv1.5')\n",
    "\n",
    "aligned_frame.append(temp)\n",
    "\n",
    "temp = {'protocol':3.0,'ALLEN':ALLEN_CV30.iloc[-1],'DM':CV_DM,'EFEL':float(EFEL_ISI_CV_30[0])}\n",
    "aligned_frame.append(temp)\n",
    "\n",
    "#aligned_f.append(temp,ignore_index=True)#index='cv3.0')\n",
    "#print(aligned_f)\n",
    "\n",
    "#import pdb\n",
    "#pdb.set_trace()\n",
    "temp = {'protocol':3.0,'EFEL':adaptation_index_EFEL.iloc[-1],'DM':accom_DM,'ALLEN':contents[0]['allen']['adapt'].iloc[-1]}\n",
    "#aligned_f = aligned_frame.append(temp)\n",
    "\n",
    "temp = {'protocol':1.5,'EFEL':adaptation_index_EFEL.iloc[0],'DM':accom_DM,'ALLEN':contents[0]['allen']['adapt'].iloc[0]}\n",
    "aligned_frame.append(temp)\n",
    "\n",
    "\n",
    "temp = {'protocol':3.0,'EFEL':time_to_first_spike_EFEL.iloc[-1],'DM':delay,'ALLEN':contents[0]['allen']['latency'].iloc[-1]}\n",
    "aligned_frame.append(temp)\n",
    "temp = {'protocol':1.5,'EFEL':time_to_first_spike_EFEL.iloc[0],'DM':delay,'ALLEN':contents[0]['allen']['latency'].iloc[0]}\n",
    "aligned_frame.append(temp)\n",
    "\n",
    "af = pd.DataFrame(aligned_frame)\n",
    "af.rename(index={1:'CV3'}, inplace=True)\n",
    "af.rename(index={0:'CV15'}, inplace=True)\n",
    "af.rename(index={3:'adaption15'}, inplace=True)\n",
    "af.rename(index={2:'adaption3'}, inplace=True)\n",
    "af.rename(index={2:'delay3'}, inplace=True)\n",
    "af.rename(index={2:'delay15'}, inplace=True)\n",
    "\n",
    "#print(af['ALLEN'].corr(af['DM']))\n",
    "\n",
    "#print(af.corr())\n",
    "print(af)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_three_vectors(three_vectors,title=None):\n",
    "    plot_vector = [i for i,_ in enumerate(three_vectors[0])]\n",
    "    for tv in three_vectors:\n",
    "        tv = (tv - np.mean(tv))/np.std(tv)\n",
    "        plt.plot(plot_vector,tv)\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "efel_CV = [ float(cont['efel']['ISI_CV'].iloc[0]) for cont in contents ]\n",
    "dm_CV = [ float(cont['dm']['ISICVTest'].iloc[0]) for cont in contents ]\n",
    "allen_CV = [ float(cont['allen']['isi_cv'].iloc[0]) for cont in contents ]\n",
    "\n",
    "scaled_allen_CV = (allen_CV - np.mean(allen_CV))/np.std(allen_CV)\n",
    "scaled_dm_CV = (dm_CV - np.mean(dm_CV))/np.std(dm_CV)\n",
    "#sklearn.preprocessing.scale(, axis=0, with_mean=True, with_std=True, copy=True)\n",
    "scaled_efel_CV = (efel_CV - np.mean(efel_CV))/np.std(efel_CV)\n",
    "three_vectors = [scaled_allen_CV, scaled_dm_CV,scaled_efel_CV]\n",
    "plot_three_vectors(three_vectors,title='CV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#sklearn.preprocessing.scale(efel_CV, axis=0, with_mean=True, with_std=True, copy=True)\n",
    "\n",
    "plt.show()\n",
    "X = list(zip(efel_CV, dm_CV))\n",
    "Y = list(zip(dm_CV,allen_CV))\n",
    "cca.fit(X,Y)\n",
    "\n",
    "cca.coef_.shape                   # (5,5)\n",
    "\n",
    "U_c, V_c = cca.transform(X, Y)\n",
    "\n",
    "U_c.shape                         # (100,1)\n",
    "V_c.shape                         # (100,1)\n",
    "##\n",
    "# wrong because needs different trace\n",
    "##\n",
    "inrh = contents[0]['efel']['ohmic_input_resistance']\n",
    "##\n",
    "# DM\n",
    "CV_DM = contents[0]['dm']['ISICVTest'].iloc[0]\n",
    "accom_DM = contents[0]['dm']['InitialAccommodationMeanTest'].iloc[0]\n",
    "inrh = contents[0]['dm']['InputResistanceTest'].iloc[0]\n",
    "delay = contents[0]['dm']['AP1DelayMeanTest'].iloc[0]\n",
    "\n",
    "# Allen\n",
    "ALLEN_CV15 = contents[0]['allen']['isi_cv'][0]#.iloc[0]\n",
    "ALLEN_CV30 = contents[0]['allen']['isi_cv'][1]#.iloc[1]\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "cca = CCA(n_components=1)\n",
    "cca.fit(U, V)\n",
    "\n",
    "cca.coef_.shape                   # (5,5)\n",
    "\n",
    "U_c, V_c = cca.transform(U, V)\n",
    "U_c.shape                         # (100,1)\n",
    "V_c.shape                         # (100,1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLEN_CV30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
